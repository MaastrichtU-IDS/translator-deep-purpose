{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c181319-064e-4fd6-96f8-fecd56f89a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dea9a5fb-b960-4eed-b1d1-188936c839a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "from translator_deep_purpose import predict_dti\n",
    "\n",
    "# Get the current date and time\n",
    "current_date_time = datetime.now()\n",
    "\n",
    "# Format the current date and time as a string\n",
    "formatted_date_time = current_date_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "results_path = f\"data/prediction_results_{formatted_date_time}.json\"\n",
    "sample_count = -1 # Use -1 to use all drugs and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7791da47-d284-46ed-b977-9053bbf72122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed datasets\n",
    "drugs_df = pd.read_csv('./data/Processed_Drugs_SMILES.csv')\n",
    "targets_df = pd.read_csv('./data/Processed_Targets_Seq.csv')\n",
    "\n",
    "# Get the drug pairs (drugID and smiles)\n",
    "drugs_pairs = drugs_df[['drugID', 'smiles']].values\n",
    "\n",
    "# Get the target pairs (targetID and sequence)\n",
    "targets_pairs = targets_df[['targetID', 'sequence']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68430d84-3834-4fdb-a7b5-614752edf106",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                MODEL MPNN_CNN_BindingDB\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00091\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00093\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00104\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00114\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00115\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00116\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00117\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00118\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00119\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00120\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00121\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00122\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00123\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00125\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00126\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00127\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00128\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00129\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00130\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00131\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00132\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00133\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00134\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00135\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00136\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00137\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00138\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00139\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00140\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00141\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00142\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00143\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00144\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00145\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00146\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00147\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00148\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00149\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00150\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00151\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00152\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00153\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00154\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00155\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00156\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00157\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00158\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00159\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00160\n",
      "       MODEL MPNN_CNN_BindingDB - DRUG drugbank:DB00161\n",
      "Results saved in combined_results.csv.\n",
      "⏱️ Total runtime: 0:10:26.812217\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "models = [\n",
    "    # BindingDB\n",
    "    \"MPNN_CNN_BindingDB\",\n",
    "    # \"CNN_CNN_BindingDB\",\n",
    "    # \"Morgan_CNN_BindingDB\",\n",
    "    # \"Transformer_CNN_BindingDB\",\n",
    "    # \"Daylight_AAC_BindingDB\",\n",
    "    # \"Morgan_AAC_BindingDB\",\n",
    "    # # BindingDB IC50\n",
    "    # \"CNN_CNN_BindingDB_IC50\",\n",
    "    # \"Morgan_CNN_BindingDB_IC50\",\n",
    "    # \"Morgan_AAC_BindingDB_IC50\",\n",
    "    # \"MPNN_CNN_BindingDB_IC50\",\n",
    "    # \"Daylight_AAC_BindingDB_IC50\",\n",
    "    # # Model pre-trained on DAVIS\n",
    "    # \"MPNN_CNN_DAVIS\",\n",
    "    # \"CNN_CNN_DAVIS\",\n",
    "    # \"Morgan_CNN_DAVIS\",\n",
    "    # \"Daylight_AAC_DAVIS\",\n",
    "    # \"Morgan_AAC_DAVIS\",\n",
    "    # # Model pre-trained on KIBA\n",
    "    # \"MPNN_CNN_KIBA\",\n",
    "    # \"Daylight_AAC_KIBA\",\n",
    "    # \"Morgan_AAC_KIBA\",\n",
    "    # \"Morgan_CNN_KIBA\", # Error 'list' object has no attribute 'float'\n",
    "]\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "time_start = datetime.now()\n",
    "\n",
    "# Get predictions for all models / all drugs / all targets in a results object\n",
    "for model in models:\n",
    "    print(\"\")\n",
    "    print(f\"                MODEL {model}\")\n",
    "    \n",
    "    for drug_id, drug_smile in drugs_pairs:\n",
    "        print(f\"       MODEL {model} - DRUG {drug_id}\")\n",
    "        \n",
    "        for target_id, target_sequence in targets_pairs:\n",
    "            try:\n",
    "                res = predict_dti(drug_smile, target_sequence, model)\n",
    "                \n",
    "                # Append result to the results list\n",
    "                results.append({\n",
    "                    \"model\": model,\n",
    "                    \"drug\": drug_id,\n",
    "                    \"target\": target_id,\n",
    "                    \"score\": res['score'],\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error predicting for [{model}] {drug_id} - {target_id} = {e}\")\n",
    "\n",
    "# Save results to a single CSV file\n",
    "csv_filename = f\"data/combined_results_{formatted_date_time}.csv\"\n",
    "with open(csv_filename, \"w\", newline=\"\") as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    \n",
    "    # Write CSV header\n",
    "    csv_writer.writerow([\"Model\", \"DrugID\", \"TargetID\", \"PredictedBindingScore\"])\n",
    "    \n",
    "    # Write data rows\n",
    "    for result in results:\n",
    "        csv_writer.writerow([result[\"model\"], result[\"drug\"], result[\"target\"], result[\"score\"]])\n",
    "\n",
    "print(\"Results saved in combined_results.csv.\")\n",
    "print(f\"⏱️ Total runtime: {datetime.now() - time_start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb365a9-3508-42af-8d9e-570a5e95f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from translator_deep_purpose import predict_dti, utils\n",
    "import csv\n",
    "from sklearn.metrics import concordance_index_score, roc_auc_score, average_precision_score\n",
    "\n",
    "# ... Your previous code ...\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "cindex_scores = []\n",
    "auroc_scores = []\n",
    "auprc_scores = []\n",
    "\n",
    "# Get predictions for all models / all drugs / all targets in a results object\n",
    "for model in models:\n",
    "    print(\"\")\n",
    "    print(f\"                MODEL {model}\")\n",
    "\n",
    "    for drug_id, drug_smile in drugs_pairs:\n",
    "        print(f\"       MODEL {model} - DRUG {drug_id}\")\n",
    "\n",
    "        for target_id, target_sequence in targets_pairs:\n",
    "            try:\n",
    "                res = predict_dti(drug_smile, target_sequence, model)\n",
    "                \n",
    "                # Get true label (y_true)\n",
    "                # You need to determine the true label for each drug-target pair\n",
    "                # Assuming you have a variable y_true containing the true labels\n",
    "\n",
    "                # Calculate evaluation metrics\n",
    "                cindex = concordance_index_score(y_true, res['score'])\n",
    "                auroc = roc_auc_score(y_true, res['score'])\n",
    "                auprc = average_precision_score(y_true, res['score'])\n",
    "\n",
    "                # Append scores to lists\n",
    "                cindex_scores.append(cindex)\n",
    "                auroc_scores.append(auroc)\n",
    "                auprc_scores.append(auprc)\n",
    "\n",
    "                # Append result to the results list\n",
    "                results.append({\n",
    "                    \"model\": model,\n",
    "                    \"drug\": drug_id,\n",
    "                    \"target\": target_id,\n",
    "                    \"score\": res['score'],\n",
    "                    \"cindex\": cindex,\n",
    "                    \"auroc\": auroc,\n",
    "                    \"auprc\": auprc,\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error predicting for [{model}] {drug_id} - {target_id} = {e}\")\n",
    "\n",
    "# ... Your code to save results ...\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Concordance Index (CI) scores:\", cindex_scores)\n",
    "print(\"AUROC scores:\", auroc_scores)\n",
    "print(\"AUPRC scores:\", auprc_scores)\n",
    "\n",
    "# Print average scores\n",
    "print(\"Average CI:\", sum(cindex_scores) / len(cindex_scores))\n",
    "print(\"Average AUROC:\", sum(auroc_scores) / len(auroc_scores))\n",
    "print(\"Average AUPRC:\", sum(auprc_scores) / len(auprc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eca3d2f-f3a2-404a-8523-d8ac79ec2722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "# Define your list of models\n",
    "models = [\n",
    "    # BindingDB\n",
    "    \"MPNN_CNN_BindingDB\",\n",
    "    # \"CNN_CNN_BindingDB\",\n",
    "    # \"Morgan_CNN_BindingDB\",\n",
    "    # \"Transformer_CNN_BindingDB\",\n",
    "    # \"Daylight_AAC_BindingDB\",\n",
    "    # \"Morgan_AAC_BindingDB\",\n",
    "    # # BindingDB IC50\n",
    "    # \"CNN_CNN_BindingDB_IC50\",\n",
    "    # \"Morgan_CNN_BindingDB_IC50\",\n",
    "    # \"Morgan_AAC_BindingDB_IC50\",\n",
    "    # \"MPNN_CNN_BindingDB_IC50\",\n",
    "    # \"Daylight_AAC_BindingDB_IC50\",\n",
    "    # # Model pre-trained on DAVIS\n",
    "    # \"MPNN_CNN_DAVIS\",\n",
    "    # \"CNN_CNN_DAVIS\",\n",
    "    # \"Morgan_CNN_DAVIS\",\n",
    "    # \"Daylight_AAC_DAVIS\",\n",
    "    # \"Morgan_AAC_DAVIS\",\n",
    "    # # Model pre-trained on KIBA\n",
    "    # \"MPNN_CNN_KIBA\",\n",
    "    # \"Daylight_AAC_KIBA\",\n",
    "    # \"Morgan_AAC_KIBA\",\n",
    "    # \"Morgan_CNN_KIBA\", # Error 'list' object has no attribute 'float'\n",
    "]\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "time_start = datetime.now()\n",
    "\n",
    "# Get predictions for all models / all drugs / all targets in a results object\n",
    "for model in models:\n",
    "    print(\"\")\n",
    "    print(f\"                MODEL {model}\")\n",
    "\n",
    "    for drug_id, drug_smile in drugs_pairs:\n",
    "        print(f\"       MODEL {model} - DRUG {drug_id}\")\n",
    "\n",
    "        for target_id, target_sequence in targets_pairs:\n",
    "            try:\n",
    "                res = predict_dti(drug_smile, target_sequence, model)\n",
    "\n",
    "                # Append result to the results list\n",
    "                results.append({\n",
    "                    \"model\": model,\n",
    "                    \"drug\": drug_id,\n",
    "                    \"target\": target_id,\n",
    "                    \"score\": res['score'],\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error predicting for [{model}] {drug_id} - {target_id} = {e}\")\n",
    "\n",
    "# Save results to a single CSV file\n",
    "formatted_date_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "csv_filename = f\"data/combined_results_{formatted_date_time}.csv\"\n",
    "with open(csv_filename, \"w\", newline=\"\") as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    # Write CSV header\n",
    "    csv_writer.writerow([\"Model\", \"DrugID\", \"TargetID\", \"PredictedBindingScore\"])\n",
    "\n",
    "    # Write data rows\n",
    "    for result in results:\n",
    "        csv_writer.writerow([result[\"model\"], result[\"drug\"], result[\"target\"], result[\"score\"]])\n",
    "\n",
    "print(\"Results saved in combined_results.csv.\")\n",
    "print(f\"⏱️ Total runtime: {datetime.now() - time_start}\")\n",
    "\n",
    "# Load the CSV file with results\n",
    "df = pd.read_csv(csv_filename)\n",
    "\n",
    "# Evaluate model performance\n",
    "evaluation_results = []\n",
    "\n",
    "for model in models:\n",
    "    model_results = df[df['model'] == model]\n",
    "    y_true = model_results['true_label']  # Replace with your true labels\n",
    "    y_pred = model_results['score']\n",
    "\n",
    "    # Calculate metrics\n",
    "    auroc = roc_auc_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred.round())\n",
    "\n",
    "    evaluation_results.append({\n",
    "        'Model': model,\n",
    "        'AUROC': auroc,\n",
    "        'F1 Score': f1\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the evaluation results and save to CSV\n",
    "evaluation_df = pd.DataFrame(evaluation_results)\n",
    "evaluation_csv_filename = f\"data/model_evaluation_{formatted_date_time}.csv\"\n",
    "evaluation_df.to_csv(evaluation_csv_filename, index=False)\n",
    "\n",
    "print(\"Model evaluation results saved in model_evaluation.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018492c7-5bad-4db1-a938-badf37ee0f7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the combined_results CSV file\n",
    "csv_filename = \"./data/combined_resultsT2D_20230815_143317.csv\"\n",
    "df = pd.read_csv(csv_filename)\n",
    "\n",
    "# Group by DrugID and calculate distribution statistics\n",
    "grouped = df.groupby('DrugID')['PredictedBindingScore'].agg(['mean', 'median', 'min', 'max'])\n",
    "\n",
    "# Write the calculated statistics to a CSV file\n",
    "statistics_filename = \"./data/statistics_resultsT2D.csv\"\n",
    "grouped.to_csv(statistics_filename)\n",
    "\n",
    "# Print the calculated statistics\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f27f68-c54a-4a05-bcee-c2ab9bcb8a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the combined_results CSV file\n",
    "csv_filename = \"./data/combined_resultsT2D_20230815_143317.csv\"\n",
    "df = pd.read_csv(csv_filename)\n",
    "\n",
    "# Group by DrugID\n",
    "grouped = df.groupby('DrugID')\n",
    "\n",
    "# Initialize dictionaries to store min and max pairs\n",
    "min_pairs = {}\n",
    "max_pairs = {}\n",
    "\n",
    "# Iterate through each group\n",
    "for drug_id, group_data in grouped:\n",
    "    # Find the row with the minimum PredictedBindingScore\n",
    "    min_row = group_data.loc[group_data['PredictedBindingScore'].idxmin()]\n",
    "    min_pairs[drug_id] = min_row\n",
    "\n",
    "    # Find the row with the maximum PredictedBindingScore\n",
    "    max_row = group_data.loc[group_data['PredictedBindingScore'].idxmax()]\n",
    "    max_pairs[drug_id] = max_row\n",
    "\n",
    "# Sort the DrugIDs\n",
    "sorted_drug_ids = sorted(min_pairs.keys())\n",
    "\n",
    "# Print min and max pairs\n",
    "print(\"Min Pairs:\")\n",
    "for drug_id in sorted_drug_ids:\n",
    "    pair = min_pairs[drug_id]\n",
    "    print(f\"DrugID: {drug_id}, TargetID: {pair['TargetID']}, Min Score: {pair['PredictedBindingScore']}\")\n",
    "\n",
    "print(\"\\nMax Pairs:\")\n",
    "for drug_id in sorted_drug_ids:\n",
    "    pair = max_pairs[drug_id]\n",
    "    print(f\"DrugID: {drug_id}, TargetID: {pair['TargetID']}, Max Score: {pair['PredictedBindingScore']}\")\n",
    "\n",
    "# Group by DrugID and create histograms\n",
    "grouped = df.groupby('DrugID')\n",
    "\n",
    "for drug_id, group_data in grouped:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(group_data['PredictedBindingScore'], bins=20, color='skyblue', edgecolor='black')\n",
    "    plt.title(f'Distribution of PredictedBindingScore for DrugID: {drug_id}')\n",
    "    plt.xlabel('PredictedBindingScore')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4b9eb8-f718-4c69-a0ed-98a2f4d7004a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "csv_filename = \"./data/combined_resultsT2D_20230815_143317.csv\"\n",
    "df = pd.read_csv(csv_filename)\n",
    "\n",
    "# Drop the 'Model' column\n",
    "df = df.drop(columns=['Model'])\n",
    "\n",
    "# Sort the DataFrame by DrugID and PredictedBindingScore\n",
    "df_sorted = df.sort_values(by=['DrugID', 'PredictedBindingScore'], ascending=[True, False])\n",
    "\n",
    "# Group by DrugID and create a list of TargetID-PredictedBindingScore pairs\n",
    "grouped = df_sorted.groupby('DrugID').apply(lambda x: list(zip(x['TargetID'], x['PredictedBindingScore'])))\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "output_filename = \"./data/sorted_resultsT2D.csv\"\n",
    "with open(output_filename, \"w\") as f:\n",
    "    f.write(\"DrugID,TargetID,PredictedBindingScore\\n\")\n",
    "    for drug_id, pairs in grouped.items():\n",
    "        for target_id, score in pairs:\n",
    "            f.write(f\"{drug_id},{target_id},{score}\\n\")\n",
    "\n",
    "print(\"Sorted results saved in sorted_resultsT2D.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453cb72d-9b9f-4a7d-b180-43ca76060950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the combined_results CSV file\n",
    "csv_filename = \"./data/combined_resultsT2D_20230815_143317.csv\"\n",
    "df = pd.read_csv(csv_filename)\n",
    "\n",
    "# Group by DrugID and calculate distribution statistics\n",
    "grouped = df.groupby('DrugID')['PredictedBindingScore'].agg(['mean', 'median', 'min', 'max'])\n",
    "grouped.reset_index(inplace=True)\n",
    "\n",
    "# Find the corresponding target for min and max scores\n",
    "min_pairs = df[df.groupby('DrugID')['PredictedBindingScore'].transform('min') == df['PredictedBindingScore']]\n",
    "max_pairs = df[df.groupby('DrugID')['PredictedBindingScore'].transform('max') == df['PredictedBindingScore']]\n",
    "\n",
    "min_pairs = min_pairs[['DrugID', 'TargetID', 'PredictedBindingScore']].rename(columns={'TargetID': 'minTarget', 'PredictedBindingScore': 'min'})\n",
    "max_pairs = max_pairs[['DrugID', 'TargetID', 'PredictedBindingScore']].rename(columns={'TargetID': 'maxTarget', 'PredictedBindingScore': 'max'})\n",
    "\n",
    "# Merge min and max pairs\n",
    "merged_pairs = pd.merge(min_pairs, max_pairs, on='DrugID')\n",
    "\n",
    "# Merge with the grouped statistics\n",
    "result_df = pd.merge(grouped, merged_pairs, on='DrugID')\n",
    "\n",
    "# Format numerical values to keep four decimal places\n",
    "result_df = result_df.round(4)\n",
    "\n",
    "# Print all drugs with statistics\n",
    "print(result_df)\n",
    "\n",
    "# Write the result to a CSV file\n",
    "result_filename = \"./data/statistics_results_formatted.csv\"\n",
    "result_df.to_csv(result_filename, index=False)\n",
    "\n",
    "print(\"Formatted results saved to:\", result_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c27a56a-692c-4ce7-8aae-550904f7acf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calc total # of DTI pairs in the test set, total # of known DTI binding pairs, and the percentage\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "csv_filename = \"./data/sorted_resultsT2D.csv\"\n",
    "df = pd.read_csv(csv_filename)\n",
    "\n",
    "# Count the total # of DTI pairs where TargetID is not null\n",
    "total_DTI_pairs = df['TargetID'].count()\n",
    "\n",
    "print(\"Total # of DTI pairs:\", total_DTI_pairs)\n",
    "\n",
    "# Count total # of known DTI binding pairs\n",
    "total_known_binding_pairs = df['knownTarget'].count()\n",
    "\n",
    "print(\"Total # of known binding pairs:\", total_known_binding_pairs)\n",
    "\n",
    "# Calculate the percentage of known binding pairs / total DTI pairs\n",
    "percentage_known_binding_pairs = (total_known_binding_pairs / total_DTI_pairs) * 100\n",
    "\n",
    "print(\"Percentage of known binding pairs / total DTI pairs (%):\", percentage_known_binding_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0d76ee-d21c-4d24-9766-fed1623a045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freq of ranking (known DTI pairs)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV file\n",
    "csv_filename = \"./data/sorted_resultsT2D.csv\"\n",
    "df = pd.read_csv(csv_filename)\n",
    "\n",
    "# Remove rows with empty cells in 'knownTarget' column\n",
    "df = df.dropna(subset=['knownTarget'])\n",
    "\n",
    "# Pivot the table to get the frequency of each ranking\n",
    "ranking_frequency = df.groupby('Ranking').size()\n",
    "\n",
    "# Plot the frequency of ranking\n",
    "ranking_frequency.plot(kind='bar')\n",
    "plt.xlabel('Ranking')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency of Ranking')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8debb6a1-c342-473f-bb30-b3be8eb479df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV file\n",
    "csv_filename = \"./data/sorted_resultsT2D.csv\"\n",
    "df = pd.read_csv(csv_filename)\n",
    "\n",
    "# Remove rows with empty cells in 'knownTarget' column\n",
    "df = df.dropna(subset=['knownTarget'])\n",
    "\n",
    "# Define the bins for aggregation\n",
    "bins = [0, 11, 22, 34]\n",
    "labels = ['[1,11]', '[12,22]', '[23,34]']\n",
    "\n",
    "# Add a new column 'RankingBucket' based on the bins\n",
    "df['RankingBucket'] = pd.cut(df['Ranking'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Pivot the table to get the frequency of each ranking bucket\n",
    "ranking_bucket_frequency = df.groupby('RankingBucket').size()\n",
    "\n",
    "# Calculate the total frequency for percentage calculation\n",
    "total_freq = ranking_bucket_frequency.sum()\n",
    "\n",
    "# Plot the frequency of ranking buckets\n",
    "ax = ranking_bucket_frequency.plot(kind='bar', figsize=(8, 6))\n",
    "plt.xlabel('Ranking')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency of Ranking Buckets')\n",
    "\n",
    "# Make the y-axis integer\n",
    "ax.yaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "\n",
    "# Add the count and percentage on top of each bar\n",
    "for bar in ax.patches:\n",
    "    count = bar.get_height()\n",
    "    percentage = (count / total_freq) * 100\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{count}\\n({percentage:.1f}%)',\n",
    "             ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf48d1b-44b9-4408-8e65-0eb19311732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq of ranking by drug\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV file\n",
    "csv_filename = \"./data/sorted_resultsT2D.csv\"\n",
    "df = pd.read_csv(csv_filename)\n",
    "\n",
    "# Remove rows with empty cells in 'knownTarget' column\n",
    "df = df.dropna(subset=['knownTarget'])\n",
    "\n",
    "# Pivot the table to get the frequency of each ranking for each drug\n",
    "drug_ranking_frequency = df.pivot_table(index='DrugID', columns='Ranking', values='PredictedBindingScore', aggfunc='count', fill_value=0)\n",
    "\n",
    "# Plot the frequency of ranking by drug\n",
    "ax = drug_ranking_frequency.plot(kind='bar', stacked=True)\n",
    "plt.xlabel('Drug')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency of Ranking by Drug')\n",
    "\n",
    "# Move the legend to the right side\n",
    "plt.legend(title='Ranking', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdf648a-1ab9-4ce1-9699-35b93f32fb11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV file\n",
    "csv_filename = \"./data/sorted_resultsT2D.csv\"\n",
    "df = pd.read_csv(csv_filename)\n",
    "\n",
    "# Remove rows with empty cells in the 'knownTarget' column\n",
    "df = df.dropna(subset=['knownTarget'])\n",
    "\n",
    "# Define the ranking buckets\n",
    "buckets = {\n",
    "    '1-One: [1,11]': range(1, 12),\n",
    "    '2-Two: [12,23]': range(12, 23),\n",
    "    '3-Three: [24,34]': range(23, 35)\n",
    "}\n",
    "\n",
    "# Map each ranking to a bucket\n",
    "df['RankingBucket'] = df['Ranking'].apply(\n",
    "    lambda ranking: next(bucket for bucket, range_ in buckets.items() if ranking in range_)\n",
    ")\n",
    "\n",
    "# Group by DrugID and RankingBucket, and count the frequencies\n",
    "drug_bucket_frequency = df.groupby(['DrugID', 'RankingBucket']).size().unstack(fill_value=0)\n",
    "\n",
    "# Plot the frequency of ranking buckets by drug\n",
    "ax = drug_bucket_frequency.plot(kind='bar', stacked=True)\n",
    "plt.xlabel('Drug')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency of Ranking Buckets for Known DTI Bindings')\n",
    "\n",
    "# Move the legend to the right side\n",
    "plt.legend(title='Ranking Buckets', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367bf8f3-a3a8-443b-b8f7-39e2536dd95b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wilcoxon rank-sum (Mann-Whitney U) test\n",
    "# Purpose: for comparing two independent groups (known DTI binding pairs vs. unknown binding pairs) when the sample sizes are imbalanced and we're interested in assessing whether the distributions of rankings differ significantly\n",
    "# comparing the rankings of known binding pairs (top x rankings) against the rankings of the unknown binding pairs (the test will provide insight into whether the known binding pairs tend to have different rankings than the unknown binding pairs within each drug)\n",
    "# H0: the distribution of rankings for known binding pairs is NOT significantly different from the distribution of rankings for unknown binding pairs within each drug\n",
    "# H1: the distribution of rankings for known binding pairs is significantly different from the distribution of rankings for unknown binding pairs within each drug\n",
    "# Interpretation: if the Wilcoxon rank-sum test yields a significant p-value for a particular drug, it indicates that the distribution of rankings for known binding pairs is significantly different from the distribution of rankings for unknown binding pairs within that drug. This suggests that the known binding pairs tend to have different rankings.\n",
    "\n",
    "# Results: acorss all drugs, the distributions of rankings are NOT significantly different...\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import ranksums\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"./data/sorted_resultsT2D.csv\")\n",
    "\n",
    "# Get unique DrugIDs\n",
    "unique_drugs = data['DrugID'].unique()\n",
    "\n",
    "# Significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Loop through unique drugs and perform Wilcoxon rank-sum test\n",
    "for drug in unique_drugs:\n",
    "    drug_data = data[data['DrugID'] == drug]\n",
    "    \n",
    "    known_ranking = drug_data[drug_data['knownTarget'].notnull()]['Ranking']\n",
    "    unknown_ranking = drug_data[drug_data['knownTarget'].isnull()]['Ranking']\n",
    "    \n",
    "    statistic, p_value = ranksums(known_ranking, unknown_ranking)\n",
    "    \n",
    "    print(f\"Drug: {drug}\")\n",
    "    print(f\"Statistic: {statistic}\")\n",
    "    print(f\"P-value: {p_value}\")\n",
    "    \n",
    "    if p_value < alpha:\n",
    "        print(\"The distributions of rankings are significantly different.\")\n",
    "    else:\n",
    "        print(\"The distributions of rankings are not significantly different.\")\n",
    "    \n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c71d4e0-5b1f-4bc2-b371-c88ff30fa414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wilcoxon signed-rank test\n",
    "# H0: there is NO significant difference between the predicted scores for known binding pairs and the predicted scores for unknown binding pairs within each drug\n",
    "# H1: the predicted scores for known binding pairs are significantly higher than the predicted scores for unknown binding pairs within each drug\n",
    "# Interpretation: if the Wilcoxon signed-rank test yields a significant p-value for a particular drug, it indicates that the predicted scores for known binding pairs are significantly higher than the predicted scores for unknown binding pairs within that drug. This suggests that the model's performance is better in terms of ranking known binding pairs higher.\n",
    "\n",
    "# results: except for Drug: Repaglinide (p-value: 0.02810804014715179, the distributions of predicted scores for known and unknown binding pairs are significantly different)\n",
    "# all the other drugs have no significant difference in the distributions of predicted scores between known and unknown binding pairs\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import ranksums\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"./data/sorted_resultsT2D.csv\")\n",
    "\n",
    "# Get unique DrugIDs\n",
    "unique_drugs = data['DrugID'].unique()\n",
    "\n",
    "# Significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Loop through unique drugs and perform Wilcoxon rank-sum test\n",
    "for drug in unique_drugs:\n",
    "    drug_data = data[data['DrugID'] == drug]\n",
    "    \n",
    "    known_scores = drug_data[drug_data['knownTarget'].notnull()]['PredictedBindingScore']\n",
    "    unknown_scores = drug_data[drug_data['knownTarget'].isnull()]['PredictedBindingScore']\n",
    "    \n",
    "    statistic, p_value = ranksums(known_scores, unknown_scores)\n",
    "    \n",
    "    print(f\"Drug: {drug}\")\n",
    "    print(f\"Statistic: {statistic}\")\n",
    "    print(f\"P-value: {p_value}\")\n",
    "    \n",
    "    if p_value < alpha:\n",
    "        print(\"The distributions of predicted scores for known and unknown binding pairs are significantly different.\")\n",
    "    else:\n",
    "        print(\"There is no significant difference in the distributions of predicted scores between known and unknown binding pairs.\")\n",
    "    \n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97912ed-39fd-4325-8198-8c2e6a562612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
