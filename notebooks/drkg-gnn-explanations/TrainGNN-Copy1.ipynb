{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80d394e1-87c1-4ee9-a182-9d056b679730",
   "metadata": {},
   "source": [
    "**------------------------------------------------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "**Input: Drug Repurposing Knowledge Graph (DRKG)**\n",
    "\n",
    "**Purpose: Return trained GraphSAGE, GCN and GAT on DRKG**\n",
    "\n",
    "**------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49067ae-adaa-41d3-8a4c-f88a8d5d89c6",
   "metadata": {},
   "source": [
    "# Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb971bee-bed7-404b-aeac-7278245b8538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import json\n",
    "\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import itertools\n",
    "import import_ipynb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "import dgl.function as fn\n",
    "from dgl.nn import HeteroGraphConv, SAGEConv, GraphConv, GATConv\n",
    "from dgl.data.utils import save_graphs, load_graphs\n",
    "\n",
    "from torch_geometric.explain import characterization_score\n",
    "\n",
    "from captum.attr import Saliency, IntegratedGradients\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f61bc32b-7685-44e1-9f62-f9d60559bd95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting captum\n",
      "  Downloading captum-0.6.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.6 in /usr/local/lib/python3.8/dist-packages (from captum) (2.0.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from captum) (3.7.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from captum) (1.22.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->captum) (11.7.99)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->captum) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->captum) (3.1.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->captum) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->captum) (2.0.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->captum) (2.14.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->captum) (3.10.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->captum) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->captum) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->captum) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->captum) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->captum) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->captum) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->captum) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->captum) (11.7.4.91)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->captum) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->captum) (1.11.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6->captum) (65.5.1)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6->captum) (0.38.4)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.8/dist-packages (from triton==2.0.0->torch>=1.6->captum) (15.0.7)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.8/dist-packages (from triton==2.0.0->torch>=1.6->captum) (3.24.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum) (1.0.7)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum) (5.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum) (1.4.4)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=3.2.0->matplotlib->captum) (3.14.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch>=1.6->captum) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch>=1.6->captum) (1.3.0)\n",
      "Installing collected packages: captum\n",
      "Successfully installed captum-0.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d82b195-cadd-457c-a9b0-1a0f1580efdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting torch_geometric\n",
      "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (5.9.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (4.65.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (1.22.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (1.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (2.28.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (1.2.0)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch_geometric) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (1.26.14)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
      "Building wheels for collected packages: torch_geometric\n",
      "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910475 sha256=de8d3d3a6fb4fccf023a349149c4ec8a0b3cd5d7ad5bc09e65ba90c9161bd46c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-w7t5osw4/wheels/ff/6c/d6/f131acff9176ff91cb7ce97ddcd7170182c99533bf31c86a1d\n",
      "Successfully built torch_geometric\n",
      "Installing collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de5f8198-9d7c-4d2c-b4aa-59524b1de113",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: import_ipynb in /usr/local/lib/python3.8/dist-packages (0.1.4)\n",
      "Requirement already satisfied: IPython in /usr/local/lib/python3.8/dist-packages (from import_ipynb) (8.11.0)\n",
      "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from import_ipynb) (5.7.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (3.0.38)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (0.7.5)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (5.1.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (2.14.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (4.8.0)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (0.6.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (0.18.2)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (0.1.6)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (5.9.0)\n",
      "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->import_ipynb) (2.16.3)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->import_ipynb) (4.17.3)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.8/dist-packages (from nbformat->import_ipynb) (5.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.16->IPython->import_ipynb) (0.8.3)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (0.19.3)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (1.3.10)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (22.2.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (5.12.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect>4.3->IPython->import_ipynb) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->IPython->import_ipynb) (0.2.6)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core->nbformat->import_ipynb) (3.1.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from stack-data->IPython->import_ipynb) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from stack-data->IPython->import_ipynb) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.8/dist-packages (from stack-data->IPython->import_ipynb) (0.2.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from asttokens>=2.1.0->stack-data->IPython->import_ipynb) (1.16.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->import_ipynb) (3.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3bde288-0ace-472c-9134-42a9b7a49549",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting dgl\n",
      "  Downloading dgl-1.1.1-cp38-cp38-manylinux1_x86_64.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from dgl) (4.65.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (1.6.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (5.9.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (2.28.2)\n",
      "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.8/dist-packages (from dgl) (2.6.3)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (1.22.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (2022.12.7)\n",
      "Installing collected packages: dgl\n",
      "Successfully installed dgl-1.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dgl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f5bd05-2ec7-4d2f-9da2-7ed0a61e5e88",
   "metadata": {},
   "source": [
    "**Parameters: define GNN variant, # features per node, # epochs to train the network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4a99f99-d507-46e9-ae91-2c71e05e8818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnn_variant = 'GAT'\n",
    "# gnn_variant = 'GraphSAGE'\n",
    "gnn_variant = 'GCN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93460dec-5d4c-43a4-8ed8-cab3f904ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_node_features = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "374b3eb6-ba73-4288-9b1f-869354cb1465",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb9f943-9c0a-43c3-86c2-6f9de5079d68",
   "metadata": {},
   "source": [
    "# 1) Create Heterogeneous Graph/Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2327a7-a0a8-4eac-872b-572e89ece7e5",
   "metadata": {},
   "source": [
    "**Get Drug Repurposing Knowledge Graph (DRKG)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f107b8a-2b8e-4377-9c03-3eba6b3dfdb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Input/drkg.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./Input/drkg.tsv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Input/drkg.tsv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./Input/drkg.tsv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "459babe5-5bd7-4b1d-b112-3ddefbc8d655",
   "metadata": {},
   "source": [
    "# Define subgraph for Alzheimer\n",
    "labels = df[(df[1] == \"DRUGBANK::treats::Compound:Disease\") & (df[2] != \"Disease::MESH:D000544\")].index\n",
    "df = df.drop(labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87825803-3099-4574-90ff-61a160563aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only consider Drug + Disease\n",
    "df = df[(df[0].str.startswith('Compound') | df[0].str.startswith('Disease')) & (df[2].str.startswith('Compound') | df[2].str.startswith('Disease'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d188f75-ded0-438f-9b45-ca076db4ba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7460ed4-3bb7-45b1-b97d-96bd0f8adafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = df.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6101fe-2805-4084-b62f-7275f33c8ca1",
   "metadata": {},
   "source": [
    "**Assign an ID to each node/entity: create a dictionary of node-types -> each dictionary further consists of a dictionary mapping a node to an ID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c63297c-ce70-4cbd-8df6-8864aca3db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_dictionary = {}\n",
    "def insert_entry(entry, ent_type, dic):\n",
    "    if ent_type not in dic:\n",
    "        dic[ent_type] = {}\n",
    "    ent_n_id = len(dic[ent_type])\n",
    "    if entry not in dic[ent_type]:\n",
    "         dic[ent_type][entry] = ent_n_id\n",
    "    return dic\n",
    "\n",
    "for triple in triplets:\n",
    "    src = str(triple[0])\n",
    "    split_src = src.split('::')\n",
    "    src_type = split_src[0]\n",
    "    dest = str(triple[2])\n",
    "    split_dest = dest.split('::')\n",
    "    dest_type = split_dest[0]\n",
    "    insert_entry(src, src_type, entity_dictionary)\n",
    "    insert_entry(dest, dest_type, entity_dictionary)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a97c87fb-b12b-420a-9c86-1b239f7183a2",
   "metadata": {},
   "source": [
    "with open(\"Input/entity_dictionary_alzheimer.json\", \"w\") as file:\n",
    "    json.dump(entity_dictionary, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0101571-e095-43ae-ad0d-a62b59a45b76",
   "metadata": {},
   "source": [
    "**Create a dictionary of relations: the key is the relation and the value is a list of (source node ID, destination node ID) tuples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fcea96f-cf8c-4ee7-a652-7ca18b59e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_dictionary = {}\n",
    "for triple in triplets:\n",
    "    src = str(triple[0])\n",
    "    split_src = src.split('::')\n",
    "    src_type = split_src[0]\n",
    "    dest = str(triple[2])\n",
    "    split_dest = dest.split('::')\n",
    "    dest_type = split_dest[0]\n",
    "    \n",
    "    src_int_id = entity_dictionary[src_type][src]\n",
    "    dest_int_id = entity_dictionary[dest_type][dest]\n",
    "    \n",
    "    pair = (src_int_id, dest_int_id)\n",
    "    etype = (src_type, triple[1], dest_type)\n",
    "    if etype in edge_dictionary:\n",
    "        edge_dictionary[etype] += [pair]\n",
    "    else:\n",
    "        edge_dictionary[etype] = [pair]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1c34d0-0259-4421-a4e6-16a0477d3f35",
   "metadata": {},
   "source": [
    "**Create HeteroGraph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e3b1029-9d6a-490d-865c-7946340660e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dgl.heterograph(edge_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1ae612-5c52-4089-8272-bd301c34be93",
   "metadata": {},
   "source": [
    "**Add some synthetic/random node features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afd64d26-d3de-4999-81c0-1a9b6731c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = {}\n",
    "for ntype in g.ntypes:\n",
    "    g.nodes[ntype].data['h'] = torch.randn(g.num_nodes(ntype), n_node_features).requires_grad_(True)\n",
    "    node_features[ntype] = g.nodes[ntype].data['h']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba15b3e-8de9-4e0f-b399-45bba81d12d2",
   "metadata": {},
   "source": [
    "**Define etype: we only want to predict one edge type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f211d965-3694-4b79-a3c1-10c5af2a66dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "etype = ('Compound', 'DRUGBANK::treats::Compound:Disease', 'Disease')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b049de-a5be-4a77-89d9-a9ee7b025d2a",
   "metadata": {},
   "source": [
    "# 2) Define Graph Neural Network (GNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9f72f5b-986d-4a13-b715-afcfd85e4b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_negative_graph(graph, k, etype):\n",
    "    utype, _, vtype = etype\n",
    "    src, dst = graph.edges(etype=etype)\n",
    "    neg_src = src.repeat_interleave(k)\n",
    "    neg_dst = torch.randint(0, graph.num_nodes(vtype), (len(src) * k,))\n",
    "    return dgl.heterograph({etype: (neg_src, neg_dst)}, num_nodes_dict = {ntype: graph.num_nodes(ntype) for ntype in graph.ntypes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4063ce97-519b-4995-93ee-46efaf64e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroDotProductPredictor(nn.Module):\n",
    "    def forward(self, graph, h, etype):\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            graph.apply_edges(fn.u_dot_v('h', 'h', 'score'), etype=etype)\n",
    "            return graph.edges[etype].data['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ed2c488-1657-43e7-b0b1-20de831df27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, etypes):\n",
    "        super().__init__()\n",
    "        if gnn_variant == 'GraphSAGE':\n",
    "            self.conv1 = HeteroGraphConv({etype: SAGEConv(10, 10, 'mean') for etype in etypes})\n",
    "            self.conv2 = HeteroGraphConv({etype: SAGEConv(10, 10, 'mean') for etype in etypes})\n",
    "            self.pred = HeteroDotProductPredictor()\n",
    "        elif gnn_variant == 'GCN':\n",
    "            self.conv1 = HeteroGraphConv({etype: GraphConv(10, 10) for etype in etypes})\n",
    "            self.conv2 = HeteroGraphConv({etype: GraphConv(10, 10) for etype in etypes})\n",
    "            self.pred = HeteroDotProductPredictor()\n",
    "        elif gnn_variant == 'GAT':\n",
    "            self.conv1 = HeteroGraphConv({etype: GATConv(10, 10, 1) for etype in etypes})\n",
    "            self.conv2 = HeteroGraphConv({etype: GATConv(10, 10, 1) for etype in etypes})\n",
    "            self.pred = HeteroDotProductPredictor()\n",
    "        else:\n",
    "            print('No model has been chosen !')\n",
    "        \n",
    "    def forward(self, pos_g, neg_g, node_features, etype, edge_weight=None):\n",
    "        if edge_weight is None:\n",
    "            h = self.conv2(pos_g, self.conv1(pos_g, node_features))\n",
    "        else:\n",
    "            h = self.conv2(pos_g, self.conv1(pos_g, node_features, mod_kwargs={etype:{'edge_weight': edge_weight[etype]} for etype in g.etypes}))\n",
    "        return self.pred(pos_g, h, etype), self.pred(neg_g, h, etype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d9d0bb-943c-456c-a400-c00c69278c2b",
   "metadata": {},
   "source": [
    "# 3) Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbf9b13-7dee-4855-aac3-c6a76b583b5b",
   "metadata": {},
   "source": [
    "**Initialize model and optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35db0403-502d-41f1-ab54-e5195486dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(g.etypes)\n",
    "opt = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d59379-1ca2-463c-8cf2-d9ade83c5821",
   "metadata": {},
   "source": [
    "**Train/test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e6191dd-1f29-4134-82b8-d92a4236fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eids = np.arange(g.number_of_edges(etype))\n",
    "eids = np.random.permutation(eids)\n",
    "eids = torch.tensor(eids, dtype=torch.int64)\n",
    "\n",
    "train_size = int(len(eids) * 0.8)\n",
    "test_size = g.number_of_edges(etype) - train_size\n",
    "\n",
    "train_indices = {etype: eids[test_size:]}\n",
    "test_indices = {etype: eids[:test_size]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3945c416-8979-41cd-bc0c-a914af2eab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_train = dgl.remove_edges(g, eids=test_indices[etype], etype=etype)\n",
    "g_test = dgl.remove_edges(g, eids=train_indices[etype], etype=etype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650988c2-9b5a-490d-92a7-ea228a9c0204",
   "metadata": {},
   "source": [
    "**Define metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59975395-133a-4196-807c-f1e32028960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(pos_score, neg_score):\n",
    "    n_edges = pos_score.shape[0]\n",
    "    return (1 - pos_score + neg_score.view(n_edges, -1)).clamp(min=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afdcf9c6-f3ab-4c67-8130-79327a49413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_auroc(pos_score, neg_score): \n",
    "    model.eval()\n",
    "    scores = torch.cat([pos_score, neg_score]).view(-1)\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
    "    return roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "\n",
    "def eval_model(pos_score, neg_score):\n",
    "    model.eval()\n",
    "    scores = torch.cat([pos_score, neg_score]).view(-1).detach().numpy()\n",
    "    scores = np.where(scores >= 0.6, 1, 0)\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).detach().numpy()\n",
    "    return precision_score(labels, scores), recall_score(labels, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5384d048-a482-4178-b8c1-9990145d28c0",
   "metadata": {},
   "source": [
    "**Train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8238abe4-2499-40f2-b8c8-868005a4fbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, AUROC: 0.4934\n",
      "Epoch: 010, AUROC: 0.6074\n",
      "Epoch: 020, AUROC: 0.7299\n",
      "Epoch: 030, AUROC: 0.8124\n",
      "Epoch: 040, AUROC: 0.8490\n",
      "Epoch: 050, AUROC: 0.8602\n",
      "Epoch: 060, AUROC: 0.8723\n",
      "Epoch: 070, AUROC: 0.8876\n",
      "Epoch: 080, AUROC: 0.8955\n",
      "Epoch: 090, AUROC: 0.9031\n",
      "Epoch: 100, AUROC: 0.9031\n",
      "Epoch: 110, AUROC: 0.9077\n",
      "Epoch: 120, AUROC: 0.9070\n",
      "Epoch: 130, AUROC: 0.9069\n",
      "Epoch: 140, AUROC: 0.9070\n",
      "Epoch: 150, AUROC: 0.9080\n",
      "Epoch: 160, AUROC: 0.9080\n",
      "Epoch: 170, AUROC: 0.9076\n",
      "Epoch: 180, AUROC: 0.9061\n",
      "Epoch: 190, AUROC: 0.9087\n",
      "Epoch: 200, AUROC: 0.9087\n",
      "Epoch: 210, AUROC: 0.9083\n",
      "Epoch: 220, AUROC: 0.9094\n",
      "Epoch: 230, AUROC: 0.9061\n",
      "Epoch: 240, AUROC: 0.9107\n",
      "Epoch: 250, AUROC: 0.9086\n",
      "Epoch: 260, AUROC: 0.9076\n",
      "Epoch: 270, AUROC: 0.9062\n",
      "Epoch: 280, AUROC: 0.9092\n",
      "Epoch: 290, AUROC: 0.9087\n",
      "Epoch: 300, AUROC: 0.9077\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs+1): \n",
    "    # forward\n",
    "    g_neg_train = construct_negative_graph(g_train, 5, etype)\n",
    "    pos_score, neg_score = model(g_train, g_neg_train, node_features, etype)\n",
    "\n",
    "    # compute loss, auroc\n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "    auroc = compute_auroc(pos_score, neg_score)\n",
    "\n",
    "    # backward\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    # print epoch + auroc\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, AUROC: {auroc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed825dd5-89f2-423a-8bd1-d309ce11d8b3",
   "metadata": {},
   "source": [
    "**Test model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5de7dc83-9d7f-4989-8636-86d0af22c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward\n",
    "g_neg_test = construct_negative_graph(g_test, 5, etype)\n",
    "pos_score, neg_score = model(g_test, g_neg_test, node_features, etype)\n",
    "\n",
    "# eval model\n",
    "precision, recall = eval_model(pos_score, neg_score)\n",
    "auroc = compute_auroc(pos_score, neg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fdeb222c-a9a4-47a2-bf8a-b50658c2cbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7978\n",
      "Recall: 0.2857\n",
      "F1-Score: 0.4207\n",
      "AUROC: 0.9377\n"
     ]
    }
   ],
   "source": [
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-Score: {f1_score:.4f}')\n",
    "print(f'AUROC: {auroc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618ee1c6-b762-4161-a391-607a2faddc57",
   "metadata": {},
   "source": [
    "**Save model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49420af1-b6d3-4bd4-b6bf-b70b5a7d4866",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f'GNNModels/{gnn_variant}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a164411-ed50-4f53-99b2-0a876ee2947b",
   "metadata": {},
   "source": [
    "# Save subgraph \n",
    "save_graphs('Input/AlzheimerGraph', g_list=[g, construct_negative_graph(g, 5, etype)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
